{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## linear regression\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference :get prediction\n",
    "def inference(w, b, x):\n",
    "    pred_y = w * x +b\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "def eval_loss(w, b, x_list, gt_y_list):\n",
    "    avg_loss = 0.0\n",
    "    for i in range(len(x_list)):\n",
    "        avg_loss += 0.5 * (w * x_list[i] + b - gt_y_list[i]) **2\n",
    "    avg_loss /= len(gt_y_list)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单次 gradient descent dw & db\n",
    "def gradient(pred_y, gt_y, x):\n",
    "    diff = pred_y - gt_y\n",
    "    dw = diff * x\n",
    "    db = diff\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始迭代计算\n",
    "def cal_step_gradient(batch_x_list, batch_gt_y_list, w, b, lr):\n",
    "    # batch 批\n",
    "    avg_dw, avg_db = 0, 0\n",
    "    batch_size = len(batch_x_list)\n",
    "    for i in range(batch_size):\n",
    "        pred_y = inference(w, b, batch_x_list[i])\n",
    "        dw, db = gradient(pred_y, batch_gt_y_list[i], batch_x_list[i])\n",
    "        avg_dw += dw\n",
    "        avg_db += db\n",
    "    avg_dw /= batch_size\n",
    "    avg_db /= batch_size\n",
    "    w -= lr * avg_dw\n",
    "    b -= lr * avg_db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练模型\n",
    "# batch_size为每次训练使用的样本数量\n",
    "def train(x_list, gt_y_list, batch_size, lr, max_iter):\n",
    "    w = 0\n",
    "    b = 0\n",
    "    num_samples = len(x_list)\n",
    "    for i in range(max_iter):\n",
    "        batch_idxs = np.random.choice(len(x_list), batch_size)\n",
    "        batch_x = [x_list[j] for j in batch_idxs]\n",
    "        batch_y = [gt_y_list[j] for j in batch_idxs]\n",
    "        w, b = cal_step_gradient(batch_x, batch_y, w, b, lr)\n",
    "        print('w:{0}, b:{1}'.format(w,b))\n",
    "        print('loss is {0}'.format(eval_loss(w, b, x_list, gt_y_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟样本数据\n",
    "def gen_sample_data():\n",
    "    w = random.randint(0, 10) + random.random()\n",
    "    b = random.randint(0, 5) + random.random()\n",
    "    num_samples = 100\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    for i in range(num_samples):\n",
    "        x = random.randint(0, 100) * random.random()\n",
    "        y = w * x + b + random.random() * random.randint(-1, 1)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "    return x_list, y_list, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    x_list, y_list, w ,b = gen_sample_data()\n",
    "    # learning_rate\n",
    "    # lr = 10 梯度爆炸\n",
    "    lr = 0.01\n",
    "    # 迭代次数\n",
    "    max_iter = 100\n",
    "    train(x_list, y_list, 50, lr, max_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:42.638208230720885, b:1.1567895161892012\n",
      "loss is 751383.4933577238\n",
      "w:-394.9804495749478, b:-8.461865690430816\n",
      "loss is 85228737.71822767\n",
      "w:3923.6189339690454, b:95.58545239236287\n",
      "loss is 8177867668.224617\n",
      "w:-28848.956582951345, b:-774.7101100068869\n",
      "loss is 443459537922.29175\n",
      "w:319340.1553020154, b:7228.57146662484\n",
      "loss is 54306401681758.48\n",
      "w:-2702501.0025804136, b:-65117.68276563796\n",
      "loss is 3889733814353127.0\n",
      "w:24762564.025009684, b:508513.90555929975\n",
      "loss is 3.26518251181258e+17\n",
      "w:-306773668.4395708, b:-6439170.682511931\n",
      "loss is 5.011428510954172e+19\n",
      "w:3511097475.992262, b:74151132.35255279\n",
      "loss is 6.564681802178347e+21\n",
      "w:-31691063567.35682, b:-672103749.2748978\n",
      "loss is 5.3481464172179625e+23\n",
      "w:228472755040.2062, b:5010322052.953838\n",
      "loss is 2.7797946091463443e+25\n",
      "w:-2315213741031.68, b:-51840658953.766754\n",
      "loss is 2.854533512384052e+27\n",
      "w:19536745241440.906, b:452173590493.82263\n",
      "loss is 2.0326950456565017e+29\n",
      "w:-206533671739650.12, b:-4480525507171.429\n",
      "loss is 2.2715429932087267e+31\n",
      "w:1829060143445080.5, b:43486028896563.15\n",
      "loss is 1.7817065937318412e+33\n",
      "w:-1.6847853216663632e+16, b:-371135359158009.4\n",
      "loss is 1.5115933108884159e+35\n",
      "w:1.6023761624627968e+17, b:3727598427246248.5\n",
      "loss is 1.3674110349039248e+37\n",
      "w:-1.8025396178257165e+18, b:-3.86146833318772e+16\n",
      "loss is 1.73022872955697e+39\n",
      "w:1.2843736631261209e+19, b:3.284528106346849e+17\n",
      "loss is 8.786145792631264e+40\n",
      "w:-1.3892062226726185e+20, b:-2.733410062512487e+18\n",
      "loss is 1.0276209021942141e+43\n",
      "w:9.795122256378769e+20, b:2.4909988121841607e+19\n",
      "loss is 5.1101370552845205e+44\n",
      "w:-9.720232041304648e+21, b:-2.0940617228278242e+20\n",
      "loss is 5.031407912991034e+46\n",
      "w:8.56437995041483e+22, b:2.0792450199650176e+21\n",
      "loss is 3.906447283899823e+48\n",
      "w:-8.014141255504244e+23, b:-1.691963596845217e+22\n",
      "loss is 3.420123267973632e+50\n",
      "w:1.1147413005642222e+25, b:2.1086900484270878e+23\n",
      "loss is 6.616566968241901e+52\n",
      "w:-9.976881665107537e+25, b:-2.4012512683157728e+24\n",
      "loss is 5.301217572799655e+54\n",
      "w:7.786089524286946e+26, b:2.0222643876928383e+25\n",
      "loss is 3.22895714874435e+56\n",
      "w:-5.737364365613961e+27, b:-1.4067869299476722e+26\n",
      "loss is 1.7531526944354377e+58\n",
      "w:7.900523523218484e+28, b:1.430807595196575e+27\n",
      "loss is 3.323383000594461e+60\n",
      "w:-8.202245756120225e+29, b:-1.7378009852932376e+28\n",
      "loss is 3.582570939615036e+62\n",
      "w:6.701217537078378e+30, b:1.6603662581017478e+29\n",
      "loss is 2.3917037299084275e+64\n",
      "w:-6.982004492159627e+31, b:-1.5348000710462998e+30\n",
      "loss is 2.596002789287368e+66\n",
      "w:7.089333473161586e+32, b:1.4678201296180169e+31\n",
      "loss is 2.676273889839946e+68\n",
      "w:-7.660785342450555e+33, b:-1.686106014303734e+32\n",
      "loss is 3.125302305814685e+70\n",
      "w:5.406191157524786e+34, b:1.4502580650372447e+33\n",
      "loss is 1.5567651172806211e+72\n",
      "w:-9.036799878552761e+35, b:-1.4867396052384602e+34\n",
      "loss is 4.3477576240257043e+74\n",
      "w:1.1631263274034902e+37, b:2.6028296786663038e+35\n",
      "loss is 7.204543551511675e+76\n",
      "w:-1.6724510369874014e+38, b:-3.1324794264320245e+36\n",
      "loss is 1.489318826648293e+79\n",
      "w:1.8747663453588454e+39, b:4.049728414955734e+37\n",
      "loss is 1.871680438355932e+81\n",
      "w:-1.5660944610299227e+40, b:-4.139871365342848e+38\n",
      "loss is 1.3063769016643676e+83\n",
      "w:1.2811756362417647e+41, b:3.307140264432317e+39\n",
      "loss is 8.742541404452639e+84\n",
      "w:-1.3752049678738566e+42, b:-2.9906560946985895e+40\n",
      "loss is 1.007105897692786e+87\n",
      "w:5.362124953752307e+42, b:1.9234703663451878e+41\n",
      "loss is 1.53211826892421e+88\n",
      "w:-5.137195129215142e+43, b:-1.0976012400664622e+42\n",
      "loss is 1.4053512708873924e+90\n",
      "w:5.804241625856309e+44, b:1.25795469185413e+43\n",
      "loss is 1.794030344557829e+92\n",
      "w:-6.092536191202805e+45, b:-1.4073356862648639e+44\n",
      "loss is 1.976801866797122e+94\n",
      "w:4.222592018338213e+46, b:1.1124442950717198e+45\n",
      "loss is 9.497057598498616e+95\n",
      "w:-3.606972622259134e+47, b:-8.820680796091703e+45\n",
      "loss is 6.929139226219385e+97\n",
      "w:4.711041998595124e+48, b:9.618700266494303e+46\n",
      "loss is 1.1818110338516071e+100\n",
      "w:-5.515508886516177e+49, b:-1.1583616853455731e+48\n",
      "loss is 1.6199319751450852e+102\n",
      "w:4.236147545086229e+50, b:1.1297519377914982e+49\n",
      "loss is 9.558271653850941e+103\n",
      "w:-3.1641408278044355e+51, b:-7.234647440276045e+49\n",
      "loss is 5.331800503072613e+105\n",
      "w:2.4395571819716164e+52, b:6.337861355819752e+50\n",
      "loss is 3.1699005226911944e+107\n",
      "w:-2.8329553865477556e+53, b:-5.870673328364945e+51\n",
      "loss is 4.2736561259776384e+109\n",
      "w:2.8662638951091416e+54, b:5.81225426069505e+52\n",
      "loss is 4.37465383756846e+111\n",
      "w:-2.330960346585531e+55, b:-5.6568990276069575e+53\n",
      "loss is 2.8937413085904366e+113\n",
      "w:1.2787179398267905e+56, b:3.8503982021722446e+54\n",
      "loss is 8.710729252651914e+114\n",
      "w:-1.1432208853159366e+57, b:-2.4336111228155356e+55\n",
      "loss is 6.95971605431214e+116\n",
      "w:1.0932335910331796e+58, b:2.4359014360250858e+56\n",
      "loss is 6.36468241525013e+118\n",
      "w:-1.1649718976176968e+59, b:-2.4390985420026905e+57\n",
      "loss is 7.226952829090214e+120\n",
      "w:1.0794856235770577e+60, b:2.2978194280694783e+58\n",
      "loss is 6.20533062564822e+122\n",
      "w:-1.1100852201561956e+61, b:-2.5680751927464177e+59\n",
      "loss is 6.562664933846558e+124\n",
      "w:1.3479893971117795e+62, b:2.82804770250509e+60\n",
      "loss is 9.67605028415792e+126\n",
      "w:-1.5218966255860435e+63, b:-3.121977849228435e+61\n",
      "loss is 1.2333498768328943e+129\n",
      "w:1.5514686900107678e+64, b:3.256792335026279e+62\n",
      "loss is 1.2817739183015176e+131\n",
      "w:-2.0158523790597147e+65, b:-4.3039039006811525e+63\n",
      "loss is 2.163963408604526e+133\n",
      "w:2.079567812666479e+66, b:4.200009819956754e+64\n",
      "loss is 2.3027983719840268e+135\n",
      "w:-1.6294668454758174e+67, b:-4.24348228883113e+65\n",
      "loss is 1.4142165604127706e+137\n",
      "w:1.7954188601948407e+68, b:4.011983241775821e+66\n",
      "loss is 1.716657401808855e+139\n",
      "w:-1.2028369606254653e+69, b:-3.119439054232967e+67\n",
      "loss is 7.706128761020245e+140\n",
      "w:1.1561138476080174e+70, b:2.582938630597756e+68\n",
      "loss is 7.1179214288888e+142\n",
      "w:-1.1988000209938098e+71, b:-2.4846055167777504e+69\n",
      "loss is 7.652681634060343e+144\n",
      "w:1.005016314980004e+72, b:2.3303980879741252e+70\n",
      "loss is 5.379165055622241e+146\n",
      "w:-1.0398157312732177e+73, b:-2.5498272182590393e+71\n",
      "loss is 5.758477708186113e+148\n",
      "w:1.3336616409463006e+74, b:2.6610299935820436e+72\n",
      "loss is 9.471009233587536e+150\n",
      "w:-1.2976215489003196e+75, b:-2.8678162819340304e+73\n",
      "loss is 8.966920831897575e+152\n",
      "w:9.346587849672094e+75, b:2.5837476636161113e+74\n",
      "loss is 4.6533164458563744e+154\n",
      "w:-9.859101953612173e+76, b:-2.105612833054916e+75\n",
      "loss is 5.176155444805455e+156\n",
      "w:1.2906762094400207e+78, b:2.687426765730565e+76\n",
      "loss is 8.87067492848124e+158\n",
      "w:-1.2324213530554623e+79, b:-2.692414859041614e+77\n",
      "loss is 8.088363553016045e+160\n",
      "w:5.995357474719975e+79, b:1.997144112934952e+78\n",
      "loss is 1.915129672518155e+162\n",
      "w:-8.030557788481353e+80, b:-1.4524348269407094e+79\n",
      "loss is 3.4336783089201556e+164\n",
      "w:5.011626264162556e+81, b:1.5499105472208152e+80\n",
      "loss is 1.3380686634794941e+166\n",
      "w:-3.516510826306768e+82, b:-9.685030675210312e+80\n",
      "loss is 6.586858114996401e+167\n",
      "w:3.842558349220554e+83, b:8.272719194250347e+81\n",
      "loss is 7.862794532514412e+169\n",
      "w:-3.8606489541966826e+84, b:-9.184054491259448e+82\n",
      "loss is 7.937817571077096e+171\n",
      "w:4.185979367440564e+85, b:8.98238221463652e+83\n",
      "loss is 9.331012146173502e+173\n",
      "w:-5.972401769801653e+86, b:-1.2086084490805356e+85\n",
      "loss is 1.8993655596873535e+176\n",
      "w:4.9563856109427935e+87, b:1.2724765007906023e+86\n",
      "loss is 1.3084218145420976e+178\n",
      "w:-4.44151619784139e+88, b:-1.0647438761348818e+87\n",
      "loss is 1.0506222743598643e+180\n",
      "w:2.9267422949734217e+89, b:7.913127601778854e+87\n",
      "loss is 4.5626108355700136e+181\n",
      "w:-2.392132919865335e+90, b:-5.826807391667639e+88\n",
      "loss is 3.0476305221835286e+183\n",
      "w:2.709376022266662e+91, b:6.189918584383264e+89\n",
      "loss is 3.9093134135040705e+185\n",
      "w:-3.60969070576721e+92, b:-7.087176906545699e+90\n",
      "loss is 6.938069384864907e+187\n",
      "w:2.485017015566216e+93, b:6.484839141483802e+91\n",
      "loss is 3.289157356106373e+189\n",
      "w:-2.5317797685625946e+94, b:-5.664837576715967e+92\n",
      "loss is 3.413536027009591e+191\n",
      "w:1.4126952786425015e+95, b:4.0507397013373903e+93\n",
      "loss is 1.0630989179117496e+193\n",
      "w:-1.6061675916862166e+96, b:-3.376845002183815e+94\n",
      "loss is 1.3737501659528635e+195\n",
      "w:1.199998321947221e+97, b:2.9467851183566545e+95\n",
      "loss is 7.669320424462214e+196\n",
      "w:-7.285136692612769e+97, b:-1.7665332775358388e+96\n",
      "loss is 2.826603858114057e+198\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
